#! /usr/bin/env python3
# -*- coding: utf-8 -*-
import base64
import json
import logging
import subprocess
import time
from datetime import datetime
from io import BytesIO
from urllib.parse import quote_plus

import httpx
import requests
from openai import OpenAI

from configuration import Config

name = "chatgpt"
openai_model = "gpt-4-turbo"
baidu_curl = ("curl --location 'https://www.baidu.com/s?wd=%s&tn=json' "
              "--header 'User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 16_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.6 Mobile/15E148 Safari/604.1'")
sd_url = "https://api.stability.ai/v2beta/stable-image/generate/ultra"
sd_gen_url = "https://api.stability.ai/v2beta/stable-image/control/structure"
sd_erase_url = "https://api.stability.ai/v2beta/stable-image/edit/erase"
sd_replace_url = "https://api.stability.ai/v2beta/stable-image/edit/search-and-replace"
sd_remove_background_url = "https://api.stability.ai/v2beta/stable-image/edit/remove-background"
sd_url_map = {'gen_by_img': sd_gen_url,
              'erase_img': sd_erase_url,
              'replace_img': sd_replace_url,
              'remove_background_img': sd_remove_background_url
              }

type_answer_call = [
    {"name": "type_answer",
     "description": "type_answer",
     "parameters": {
         "type": "object",
         "properties": {
             "type": {
                 "type": "string",
                 "description": "the type of question, "
                                "if user wants you to generate images please return the 'gen-img', "
                                "if user wants you to analyze images please return the 'analyze-img', "
                                "if it is a normal chat to return the 'chat', "
                                "if the content requires online search You search in context first "
                                "and if there is no information, please return the 'search'"
             },
             "answer": {
                 "type": "string",
                 "description": "the answer of content, "
                                "if type is chat, please put your answer in this field"
                                "if type is analyze-img, è¯·å¸®å¿™æ¶¦è‰²ç”¨æˆ·çš„å†…å®¹,ä»¥ä¾¿äºæ›´å¥½çš„åˆ†æå†…å®¹"
                                "if type is gen-img, This can be empty"
                                "if type is search, è¯·åœ¨æ­¤å­—æ®µä¸­è¿”å›è¦æœç´¢çš„å†…å®¹å…³é”®è¯, å¿…é¡»æ˜¯ä¸­æ–‡"
             },
         },
         "required": ["type", "answer"]
     }
     }]

img_type_answer_call = [
    {"name": "img_type_answer_call",
     "description": "img_type_answer_call",
     "parameters": {
         "type": "object",
         "properties": {
             "type": {
                 "type": "string",
                 "description": "Based on the user description, determine which of the following types it belongs to: "
                                "generate image (gen_by_img), "
                                "erase object from image (erase_img), "
                                "replace object in image (replace_img), "
                                "remove image background (remove_background_img). "
                                "Please provide the type."
             },
             "answer": {
                 "type": "string",
                 "description": "Here is your answer, please put your answer in this field"
             },
         },
         "required": ["type", "answer"]
     }
     }]


def fetch_stream(ret, is_f=False):
    rsp = ''
    for stream_res in ret:
        if is_f:
            if stream_res.choices[0].delta.function_call:
                rsp += stream_res.choices[0].delta.function_call.arguments.replace('\n\n', '\n')
        else:
            if stream_res.choices[0].delta.content:
                rsp += stream_res.choices[0].delta.content.replace('\n\n', '\n')
    return rsp


class ChatGPT:

    def __init__(self) -> None:
        self.LOG = logging.getLogger("ChatGPT")
        self.config = Config().LLM_BOT
        # openaiæ± å­
        self.openai_pool = [
            OpenAI(timeout=30, api_key=self.config.get("key1")),
            OpenAI(timeout=30, api_key=self.config.get("key2")),
            OpenAI(timeout=30, api_key=self.config.get("key3")),
        ]
        # è½®è®­è´Ÿè½½openaiæ± å­çš„è®¡æ•°å™¨
        self.count = 0
        # æ˜¯å¦æœ‰ä»£ç†ä»£ç†
        proxy = self.config.get("proxy")
        if proxy:
            for value in self.openai_pool:
                value.http_client = httpx.Client(proxies=proxy)
        # å¯¹è¯å†å²å®¹å™¨
        self.conversation_list = {}
        # æç¤ºè¯åŠ è½½
        self.system_content_msg = {"role": "system", "content": self.config.get("prompt")}
        self.system_content_msg2 = {"role": "system", "content": self.config.get("prompt2")}
        self.system_content_msg3 = {"role": "system", "content": self.config.get("prompt3")}
        self.system_content_msg4 = {"role": "system", "content": self.config.get("prompt4")}
        self.system_content_msg5 = {"role": "system", "content": self.config.get("prompt5")}
        self.system_content_msg6 = {"role": "system", "content": self.config.get("prompt6")}

    def get_xun_wen(self, question):
        content = question.split("-")[1]
        return self.send_gpt_by_message([self.system_content_msg3, {"role": "user", "content": content}])

    def send_gpt_by_message(self, messages, function_call=None, functions=None):
        try:

            # å‘é€è¯·æ±‚
            ret = self.train_openai_client().chat.completions.create(
                model=openai_model,
                messages=messages,
                temperature=0.2,
                function_call=function_call,
                functions=functions,
                stream=True
            )
            # è·å–streamæŸ¥è¯¢
            rsp = fetch_stream(ret, functions)
        except Exception as e0:
            rsp = "An unknown error has occurred. Try again later."
            self.LOG.error(str(e0))
        return rsp

    def send_chatgpt(self, real_model, wxid, openai_client):
        try:
            # å‘é€è¯·æ±‚
            question = self.conversation_list[wxid][-1]
            ret = openai_client.chat.completions.create(
                model=real_model,
                messages=self.conversation_list[wxid],
                temperature=0.2,
                function_call={"name": "type_answer"},
                functions=type_answer_call,
                stream=True
            )
            # è·å–streamæŸ¥è¯¢
            rsp = fetch_stream(ret, True)
            result = json.loads(rsp)
            self.LOG.info(f"openai result :{result}")
            if result['type'] == 'search':
                rsp = ''
                # å…ˆå»ç™¾åº¦è·å–æ•°æ®
                send_curl = baidu_curl % quote_plus(result['answer'])
                self.LOG.info(f"need go to baidu search: {result['answer']}, curl:{send_curl}")
                baidu_response = subprocess.run(send_curl, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                                                text=True)
                # è·å–å‘½ä»¤è¾“å‡º
                # ä½¿ç”¨json.loadsè§£æå“åº”ä½“
                data = json.loads(baidu_response.stdout)
                # ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ä»æ¯ä¸ªentryä¸­æå–å­—æ®µçš„å€¼
                reference_list = [
                    {"content": entry['abs'], "source_url": entry['url']}
                    for entry in data['feed']['entry']
                    if 'abs' in entry and 'url' in entry
                ]
                # å­˜å‚¨ç»“æœ
                self._update_message(wxid, "é’ˆå¯¹è¿™ä¸ªå›ç­”, å‚è€ƒä¿¡æ¯å’Œæ¥æºé“¾æ¥å¦‚ä¸‹:" + json.dumps(reference_list),
                                     "assistant")
                temp_prompt = {"role": "system",
                               "content": "ä¸‹é¢ä½ çš„å›ç­”å¿…é¡»ç»“åˆä¸Šä¸‹æ–‡,å› ä¸ºä¸Šä¸‹æ–‡éƒ½æ˜¯è”ç½‘æŸ¥è¯¢çš„,å°¤å…¶æ˜¯æ¥æºå’Œå‚è€ƒé“¾æ¥ï¼Œ"
                                          "æ‰€ä»¥ç›¸å½“äºä½ å¯ä»¥è”ç½‘è·å–ä¿¡æ¯, æ‰€ä»¥ä¸å…è®¸è¯´ä½ ä¸å¯ä»¥è”ç½‘"
                                          "å¦å¤–å¦‚æœä½ ä¸çŸ¥é“å›ç­”ï¼Œè¯·ä¸è¦ä¸è¦èƒ¡è¯´. "
                                          "å¦‚æœç”¨æˆ·è¦æ±‚æ–‡ç« æˆ–è€…é“¾æ¥è¯·ä½ æŠŠæœ€ç›¸å…³çš„å‚è€ƒé“¾æ¥ç»™å‡º(å‚è€ƒé“¾æ¥å¿…é¡»åœ¨ä¸Šä¸‹æ–‡å‡ºç°è¿‡)"}
                # ç„¶åå†æ‹¿ç»“æœå»é—®chatgpt
                self._update_message(wxid, question['content'], "user")
                ret = openai_client.chat.completions.create(
                    model=real_model,
                    messages=self.conversation_list[wxid] + [temp_prompt],
                    temperature=0.2,
                    stream=True
                )
                # è·å–streamæŸ¥è¯¢
                rsp = fetch_stream(ret)
                search_tail = f"\n- - - - - - - - - - - -\n\nğŸ•µ ğŸ¾ğŸ’©æœç´¢ï¼š{result['answer']}"
                rsp = json.dumps({"type": "chat", "answer": rsp + search_tail})
                self.LOG.info(f"openai+baidu:{rsp}")
            self._update_message(wxid, rsp, "assistant")
        except Exception as e0:
            rsp = json.dumps({"type": "chat", "answer": "å‘ç”ŸæœªçŸ¥é”™è¯¯, ç¨åå†è¯•è¯•æ"})
            self.LOG.exception('è°ƒç”¨åŒ—ç¾aiæœåŠ¡å‘ç”Ÿé”™è¯¯, msg: %s', e0)
        return rsp

    def get_answer(self, question: str, wxid: str, sender: str) -> str:
        self._update_message(wxid, question.replace("debug", "", 1), "user")
        openai_client = self.train_openai_client()
        start_time = time.time()
        self.LOG.info("å¼€å§‹å‘é€ç»™chatgptï¼Œ å…¶ä¸­real_key: %s, real_model: %s", openai_client.api_key[-4:], openai_model)
        rsp = self.send_chatgpt(openai_model, wxid, openai_client)
        end_time = time.time()
        cost = round(end_time - start_time, 2)
        self.LOG.info("chatå›ç­”æ—¶é—´ä¸ºï¼š%s ç§’", cost)
        if question.startswith('debug'):
            resp_object = json.loads(rsp)
            resp_object[
                'debug'] = f"(aiCost: {cost}s, ioCost: $s, use: {openai_client.api_key[-4:]}, model: {openai_model})"
            return json.dumps(resp_object)
        else:
            return rsp

    def _update_message(self, wxid: str, aq: str, role: str) -> None:
        time_mk = f"å½“éœ€è¦å›ç­”æ—¶é—´æ—¶è¯·ç›´æ¥å‚è€ƒå›å¤(è¯·æ³¨æ„è¿™æ˜¯ç¾å›½ä¸­éƒ¨æ—¶é—´, å¦å¤–åˆ«äººé—®ä½ æ˜¯å¦å¯ä»¥è”ç½‘ä½ éœ€è¦è¯´æˆ‘å·²ç»æ¥å…¥è°·æ­Œæœç´¢, çŸ¥è¯†åº“æœ€æ–°æ¶ˆæ¯æ˜¯å½“å‰æ—¶é—´): {str(datetime.now().strftime('%Y-%m-%d %H:%M:%S'))}"
        # åˆå§‹åŒ–èŠå¤©è®°å½•,ç»„è£…ç³»ç»Ÿä¿¡æ¯
        if wxid not in self.conversation_list.keys():
            self.conversation_list[wxid] = [
                self.system_content_msg if wxid not in self.config.get("gpt4") else self.system_content_msg2,
                {"role": "system", "content": time_mk}
            ]

        # å½“å‰é—®é¢˜
        content_question_ = {"role": role, "content": aq}
        self.conversation_list[wxid].append(content_question_)

        # åˆ·æ–°å½“å‰æ—¶é—´
        self.conversation_list[wxid][1] = {"role": "system", "content": time_mk}
        # åªå­˜å‚¨10æ¡è®°å½•ï¼Œè¶…è¿‡æ»šåŠ¨æ¸…é™¤
        if len(self.conversation_list[wxid]) > 10:
            self.LOG.info("æ»šåŠ¨æ¸…é™¤èŠå¤©è®°å½•ï¼š%s", wxid)
            # åˆ é™¤å¤šä½™çš„è®°å½•ï¼Œå€’ç€åˆ ï¼Œä¸”è·³è¿‡ç¬¬äºŒä¸ªçš„ç³»ç»Ÿæ¶ˆæ¯
            del self.conversation_list[wxid][2]

    def get_analyze_by_img(self, content, img_path):
        rsp = ''
        try:
            start_time = time.time()
            self.LOG.info("get_analyze_by_img start")
            ret = self.train_openai_client().chat.completions.create(
                model='gpt-4o',
                messages=[
                    self.system_content_msg6,
                    {"role": "user", "content": [
                        {"type": "text", "text": content},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/png;base64,{img_path}"}
                         }
                    ]}
                ],
                temperature=0.2,
                stream=True
            )
            self.LOG.info(f"get_analyze_by_img cost:[{(time.time() - start_time) * 1000}ms]")
            # è·å–streamæŸ¥è¯¢
            return fetch_stream(ret)
        except requests.Timeout:
            self.LOG.error(f"get_analyze_by_img timeout")
            raise
        except Exception:
            self.LOG.exception(f"get_analyze_by_img error")
            raise

    def get_img_by_img(self, content, img_path):
        # First get the image prompt
        image_prompt = {}
        try:
            start_time = time.time()
            self.LOG.info("ds.img.prompt start")
            image_prompt = self.send_gpt_by_message(
                messages=[
                    self.system_content_msg5 if img_path else self.system_content_msg4,
                    {"role": "user", "content": content}
                ],
                function_call={"name": "img_type_answer_call"},
                functions=img_type_answer_call,
            )
            image_prompt = json.loads(image_prompt)
            self.LOG.info(f"ds.prompt cost:[{(time.time() - start_time) * 1000}ms] result:{image_prompt}")
        except Exception:
            self.LOG.exception(f"generate_prompt error")

        # Re-generate the image based on the prompt
        try:
            start_time = time.time()
            self.LOG.info("ds.img start")
            response = requests.post(
                sd_url_map.get(image_prompt["type"], sd_url),
                headers={
                    "authorization": f"Bearer {Config().PLATFORM_KEY['sd']}",
                    "accept": "application/json; type=image/"
                },
                files={
                    "image": BytesIO(base64.b64decode(img_path))
                },
                data={
                    "prompt": image_prompt["answer"],
                    "search_prompt": image_prompt["answer"],
                    "control_strength": 0.7,
                    "output_format": "png"
                },
            )
            self.LOG.info(f"ds.img cost:[{(time.time() - start_time) * 1000}ms]")
            if response.status_code == 200:
                return {"prompt": image_prompt["answer"], "img": response.json()['image']}
            else:
                self.LOG.error(f"generate_image_with_sd not 200, result:{response.json()}")
                raise ValueError("ç”Ÿæˆå¤±è´¥! å†…å®¹å¤ªä¸å ªå…¥ç›®å•¦~")
        except requests.Timeout:
            self.LOG.error(f"generate_image_with_sd timeout")
            raise
        except Exception:
            self.LOG.exception(f"generate_image_with_sd error")
            raise

    def get_img(self, content):
        # First get the image prompt
        image_prompt = ""
        try:
            start_time = time.time()
            self.LOG.info("ds.img.prompt start")
            image_prompt = self.send_gpt_by_message(messages=[
                {"role": "system", "content": self.config.get("prompt4")},
                {"role": "user", "content": content}
            ])
            self.LOG.info(f"ds.prompt cost:[{(time.time() - start_time) * 1000}ms]")
        except Exception:
            self.LOG.exception(f"generate_prompt error")

        # Re-generate the image based on the prompt
        try:
            start_time = time.time()
            self.LOG.info("ds.img start")
            response = requests.post(sd_url,
                                     headers={
                                         "authorization": f"Bearer {Config().PLATFORM_KEY['sd']}",
                                         "accept": "application/json; type=image/"
                                     },
                                     files={"none": ''},
                                     data={
                                         "prompt": image_prompt,
                                         "output_format": "png",
                                         "aspect_ratio": "1:1"
                                     },
                                     )
            self.LOG.info(f"ds.img cost:[{(time.time() - start_time) * 1000}ms]")
            if response.status_code == 200:
                return {"img": response.json()['image'], "prompt": image_prompt}
            else:
                self.LOG.error(f"generate_image_with_sd not 200, result:{response.json()}")
                raise ValueError("ç”Ÿæˆå¤±è´¥! å†…å®¹å¤ªä¸å ªå…¥ç›®å•¦~")
        except requests.Timeout:
            self.LOG.error(f"generate_image_with_sd timeout")
            raise
        except Exception:
            self.LOG.exception(f"generate_image_with_sd error")
            raise

    def train_openai_client(self):
        self.count += 1
        return self.openai_pool[self.count % 3]


if __name__ == "__main__":
    LOG = logging.getLogger("chatgpt")
    config: dict = Config().LLM_BOT
    if not config:
        LOG.info("chatgpté…ç½®ä¸¢å¤±, æµ‹è¯•è¿è¡Œå¤±è´¥")
        exit(0)
    chat = ChatGPT()
    # æµ‹è¯•ç¨‹åº
    while True:
        q = input(">>> ")
        try:
            time_start = datetime.now()  # è®°å½•å¼€å§‹æ—¶é—´
            LOG.info(chat.get_answer(q, "", ""))
            time_end = datetime.now()  # è®°å½•ç»“æŸæ—¶é—´
            LOG.info(f"{round((time_end - time_start).total_seconds(), 2)}s")  # è®¡ç®—çš„æ—¶é—´å·®ä¸ºç¨‹åºçš„æ‰§è¡Œæ—¶é—´ï¼Œå•ä½ä¸ºç§’/s
        except Exception as e:
            LOG.error(e)
